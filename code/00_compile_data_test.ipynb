{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6faf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.stats import weightstats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc7acf",
   "metadata": {},
   "source": [
    "# Catawba [05/22]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79417e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load catawba manual data\n",
    "mandf0 = pd.read_excel(\"../data/manual/05_2022/validation_man.xlsx\")\n",
    "\n",
    "# Assume flat ground \n",
    "# Use the angle(θ) and distance from the base of the tree (d) to calculate tree height (h)\n",
    "\n",
    "# Convert slope (%) to radians\n",
    "mandf0['angle_rad'] = np.arctan(mandf0['angle']*0.01)\n",
    "\n",
    "# angle in degrees\n",
    "mandf0['angle_deg'] = np.rad2deg(mandf0['angle_rad'])\n",
    "\n",
    "# compute tree height = tan(θ) * distance (d) + viewer height \n",
    "mandf0['height_ft'] = np.tan(mandf0['angle_rad']) * mandf0['distance'] + 5.375 # John height = 64.5 in == 5.375 ft\n",
    "\n",
    "# Convert ft --> in \n",
    "mandf0['height'] = mandf0['height_ft'] * 12.\n",
    "\n",
    "# Fill in the tree heights that were measured without clinometer (shorties)\n",
    "mandf0['height'][np.isnan(mandf0['height_ft'])] = mandf0['height_in']\n",
    "\n",
    "# inches to cm\n",
    "mandf0['diam'] = mandf0['diam']*2.54\n",
    "mandf0['height'] = mandf0['height']*2.54\n",
    "\n",
    "# add col with measurement approaches \n",
    "mandf0['method'] = 'manual_0'\n",
    "\n",
    "# add col with site \n",
    "mandf0['site'] = 'catawba'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8443ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d23c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read db dump\n",
    "measurements = []\n",
    "for line in open('../data/app/05_2022/bquxjob_4eb29efb_180f7d82eb2.json', 'r'):\n",
    "    measurements.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f2002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the relevant info \n",
    "outrows = []\n",
    "for idx,tree in enumerate(measurements):\n",
    "    diam = float(measurements[idx]['diameter']['value']) * 2.54 # in to cm\n",
    "    height = float(measurements[idx]['height']['value']) * 2.54 # in to cm\n",
    "    unit = measurements[idx]['height']['unit']\n",
    "    species = measurements[idx]['speciesName']\n",
    "    date = measurements[idx]['captureDate']\n",
    "    parcel = measurements[idx]['parcelId']\n",
    "    lat = measurements[idx]['lat']\n",
    "    lon = measurements[idx]['long']\n",
    "    tree_id = measurements[idx]['id']\n",
    "    diam_url = measurements[idx]['photos'][0]['url']\n",
    "    height_url = measurements[idx]['photos'][1]['url']\n",
    "\n",
    "    treedf = pd.DataFrame([date,lat,lon,tree_id,diam,height,species,height_url, diam_url,parcel]).T\n",
    "    treedf.columns = ['date','lat','lon','tree_id','diam','height','species','height_url', 'diam_url','parcel_id']\n",
    "    outrows.append(treedf)\n",
    "    \n",
    "# concat \n",
    "valdf = pd.concat(outrows, axis = 0)\n",
    "valdf['date'] = pd.to_datetime(valdf['date'])\n",
    "valdf = valdf.sort_values(by='date', ascending = True)\n",
    "\n",
    "# Isolate field campaign dates\n",
    "mask = (valdf['date'] >= \"2022-05-12\") & (valdf['date'] <= '2022-05-14')\n",
    "appdf = valdf[mask]\n",
    "appdf = appdf.sort_values(by='date', ascending = True)[1:]\n",
    "pid = list(appdf['parcel_id'])[0]\n",
    "appdf['parcel_id'] = pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da259def",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (valdf['date'] >= \"2022-05-12\") & (valdf['date'] <= '2022-05-14')\n",
    "appdf = valdf[mask]\n",
    "appdf = appdf.sort_values(by='date', ascending = True)[1:]\n",
    "pid = list(appdf['parcel_id'])[0]\n",
    "appdf['parcel_id'] = pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b96bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compdf = pd.merge(appdf, mandf0, on = 'tree_id')\n",
    "compdf.rename(columns = {'diam_x':'diam_app', 'diam_y':'diam', 'height_x':'height_app', 'height_y':'height'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "compdf.to_csv(\"../data/catawba_05_22.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec777740",
   "metadata": {},
   "source": [
    "# Kentland [10/22]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefbf094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the manual dataframes\n",
    "mandf1 = pd.read_excel(\"../data/manual/10_2022/Working Tree Kentland 2022_SP.xlsx\", sheet_name = \"Kentland 1\")\n",
    "mandf2 = pd.read_excel(\"../data/manual/10_2022/Working Tree Kentland 2022_SP.xlsx\", sheet_name = \"Kentland 2\")\n",
    "\n",
    "# ft --> inches \n",
    "mandf1['height_1'] = mandf1['Height (ft)'] * 12\n",
    "mandf2['height_2'] = mandf2['Height (ft)'] * 12\n",
    "mandf1['diam_1'] = mandf1[\"DBH (In)\"] * 2.54 # in to cm\n",
    "mandf2['diam_2'] = mandf2[\"DBH (In)\"] * 2.54 # in to cm\n",
    "\n",
    "# add col with measurement approaches \n",
    "mandf1['method'] = 'manual 1'\n",
    "mandf2['method'] = 'manual 2'\n",
    "\n",
    "# add col with site \n",
    "mandf2['site'] = 'kentland'\n",
    "mandf1['site'] = 'kentland'\n",
    "\n",
    "mandf1_clean = mandf1.drop([\"Height (ft)\", \"DBH (In)\"], axis = 1)\n",
    "mandf2_clean = mandf2.drop([\"Height (ft)\", \"DBH (In)\"], axis = 1)\n",
    "\n",
    "# Merge back\n",
    "manual_10_22= pd.merge(mandf1_clean, mandf2_clean, right_on=['Row#','Tree#'], left_on = ['Row#','Tree#'], how='outer')\n",
    "manual_10_22['height_mean'] = manual_10_22[['height_1','height_2']].mean(axis = 1)\n",
    "manual_10_22['diam_mean'] = manual_10_22[['diam_1','diam_2']].mean(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b9edf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b136d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load app sampling datasets and do lots of formatting\n",
    "# Read db dump\n",
    "measurements = []\n",
    "for line in open('../data/app/10_2022/validation_10_2022.json', 'r'):\n",
    "    measurements.append(json.loads(line))\n",
    "\n",
    "# Extract trees line by line\n",
    "\n",
    "outrows = []\n",
    "\n",
    "for idx,tree in enumerate(measurements):\n",
    "    try:\n",
    "        diam = measurements[idx]['diameter']['value']\n",
    "        height = measurements[idx]['height']['value']\n",
    "        unit = measurements[idx]['height']['unit']\n",
    "        species = measurements[idx]['speciesName']\n",
    "        date = measurements[idx]['captureDate']\n",
    "        parcel = measurements[idx]['parcelId']\n",
    "        lat = measurements[idx]['lat']\n",
    "        lon = measurements[idx]['long']\n",
    "        tree_id = measurements[idx]['id']\n",
    "        diam_url = measurements[idx]['photos'][0]['url']\n",
    "        height_url = measurements[idx]['photos'][1]['url']\n",
    "        notes = measurements[idx]['notes']\n",
    "\n",
    "        treedf = pd.DataFrame([date,lat,lon,tree_id,diam,height,species,height_url, diam_url,parcel, notes]).T\n",
    "        treedf.columns = ['date','lat','lon','tree_id','diam','height','species','height_url', 'diam_url','parcel_id','notes']\n",
    "        outrows.append(treedf)\n",
    "        \n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "# concat \n",
    "valdf = pd.concat(outrows, axis = 0)\n",
    "valdf['date'] = pd.to_datetime(valdf['date'])\n",
    "valdf = valdf.sort_values(by='date', ascending = True)\n",
    "\n",
    "# Filter out parcels with a single measurement - this leaves just Sanjok x2 and Brenda \n",
    "valdf = pd.concat(outrows, axis = 0)\n",
    "valdf['date'] = pd.to_datetime(valdf['date'])\n",
    "valdf = valdf.sort_values(by='date', ascending = True)\n",
    "# Count n rows in each parcel \n",
    "valdf['parcel_id'].value_counts()\n",
    "# record \n",
    "counts = valdf['parcel_id'].value_counts(dropna=False) \n",
    "valids = counts[counts>1].index\n",
    "# filter \n",
    "appdf = valdf[valdf['parcel_id'].isin(valids)]\n",
    "# Extract the indices for each tree\n",
    "\n",
    "notescol = list(appdf['notes'])\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "\n",
    "for x in notescol:\n",
    "    xstr = x.lower()\n",
    "    rows.append(re.sub('[^0-9]','', xstr.split(\"p\")[0]))\n",
    "    cols.append(re.sub('[^0-9]','', xstr.split(\"p\")[1]))\n",
    "\n",
    "# Apply indices  \n",
    "appdf['row'] = rows\n",
    "appdf['tree_idx'] = cols\n",
    "\n",
    "appdf['row'] = appdf['row'].astype(float)\n",
    "appdf['tree_idx'] = appdf['tree_idx'].astype(float)\n",
    "appdf['diam'] = appdf['diam'].astype(float) * 2.54 # in to cm\n",
    "appdf['height'] = appdf['height'].astype(float) * 2.54 # in to cm \n",
    "appdf['lat'] = appdf['lat'].astype(float)\n",
    "appdf['lon'] = appdf['lon'].astype(float)\n",
    "\n",
    "appdf.replace({'parcel_id':{'5F2EA33C-65AD-4826-BF5C-D585E410C877':'User 1',\n",
    "                           'A57E7C65-8B5C-43B2-9110-5A6A4ECFBC35':'User 1 repeat',\n",
    "                           '48A3274A-5E61-4644-8C5E-0E856E87AF4F':'User 2'}}, inplace = True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16b33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs = []\n",
    "\n",
    "# For each tree (unique row / col combo index), calculate mean and variance for errorbar plots \n",
    "for ridx in appdf['row'].unique():\n",
    "    ardf = appdf[appdf['row']==ridx]\n",
    "    mrdf = manual_10_22[manual_10_22['Row#'] == ridx]\n",
    "    for tidx in appdf['tree_idx'].unique():\n",
    "        atdf = ardf[ardf['tree_idx'] == tidx]\n",
    "        mtdf = mrdf[mrdf['Tree#'] == tidx]\n",
    "        if len(atdf) > 0 and len(mtdf) > 0:\n",
    "            app_tree_df = pd.DataFrame([atdf['diam'].mean(),atdf['diam'].std(), len(atdf['diam'])]).T\n",
    "            man_tree_df = pd.DataFrame([mtdf[['diam_1','diam_2']].values.mean(),mtdf[['diam_1','diam_2']].values.std(), len(mtdf[['diam_1','diam_2']].values), mtdf['SN_x'].iloc[0],mtdf['Species_x'].iloc[0]]).T\n",
    "            app_tree_df.columns = ['app mean','app var','app n']\n",
    "            man_tree_df.columns = ['man mean','man var','man n', 'tree idx', 'species']\n",
    "            \n",
    "            odf = pd.concat([app_tree_df,man_tree_df], axis = 1)\n",
    "            \n",
    "            tdfs.append(odf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ea07f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "appdf_mean = pd.concat(tdfs).reset_index().drop(\"index\", axis = 1).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fd79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "groups = appdf_mean.groupby('species')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.errorbar(group['man mean'],\n",
    "             group['app mean'],\n",
    "             yerr=group['app var'], \n",
    "             xerr = group['man var'], \n",
    "             linestyle=\"None\", marker='o',capsize=5, label=name, markersize = 6, alpha = 0.5)\n",
    "    \n",
    "# Plot 1-1 line\n",
    "ax.plot([0,300],[0,300],'k-', lw=2, label = '1-1 line')\n",
    "\n",
    "# Compute regression \n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(appdf_mean['man mean'].astype(float), appdf_mean['app mean'])\n",
    "\n",
    "# Mean absolute error\n",
    "mae = np.nanmean((appdf_mean['man mean'] - appdf_mean['app mean']))\n",
    "mae_std = np.nanstd((appdf_mean['man mean'] - appdf_mean['app mean']))\n",
    "mape = np.nanmean(((appdf_mean['man mean'] - appdf_mean['app mean']) / appdf_mean['man mean'])) * 100\n",
    "mape_std = np.nanstd(((appdf_mean['man mean'] - appdf_mean['app mean']) / appdf_mean['man mean'])) * 100\n",
    "rmse = ((appdf_mean['man mean'] - appdf_mean['app mean']) ** 2).mean() ** .5\n",
    "\n",
    "# regression line \n",
    "line = slope*np.linspace(0,300)+ intercept\n",
    "plt.plot(np.linspace(0,300), line, 'r', label='y={:.2f}x+{:.2f}'.format(slope,intercept))\n",
    "plt.annotate(\"$R^2$ = {}\".format(str(r_value**2)[:5]), [35,20])\n",
    "plt.annotate(\"$p$ = {:.2e}\".format(p_value), [35,18])\n",
    "plt.annotate(\"Mean err = {} +/- {} cm\".format(str(round(mae,5))[:5],str(round(mae_std,2))), [35,16])\n",
    "plt.annotate(\"Mean % err = {} +/- {} %\".format(str(round(mape,5))[:5],str(round(mape_std,2))), [35,14])\n",
    "plt.annotate(\"RMSE = {} cm\".format(str(round(rmse,5))[:5],), [35,12])\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlim(10,50)\n",
    "ax.set_ylim(10,50)\n",
    "    \n",
    "plt.xlabel(\"manual diameter (cm)\", size = 16)\n",
    "plt.ylabel(\"app-based diameter (cm)\", size = 16)\n",
    "\n",
    "\n",
    "titlestr = \"Kentland Diameter (cm), N = {}\".format(str(len(appdf_mean)))\n",
    "plt.title(titlestr, size = 20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d48027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the manual dataframes\n",
    "mandf1 = pd.read_excel(\"../data/manual/10_2022/Working Tree Kentland 2022_SP.xlsx\", sheet_name = \"Kentland 1\")\n",
    "mandf2 = pd.read_excel(\"../data/manual/10_2022/Working Tree Kentland 2022_SP.xlsx\", sheet_name = \"Kentland 2\")\n",
    "\n",
    "# ft --> inches \n",
    "mandf1['height_1'] = mandf1['Height (ft)'] * 12\n",
    "mandf2['height_2'] = mandf2['Height (ft)'] * 12\n",
    "mandf1['diam_1'] = mandf1[\"DBH (In)\"] * 2.54 # in to cm\n",
    "mandf2['diam_2'] = mandf2[\"DBH (In)\"] * 2.54 # in to cm\n",
    "\n",
    "# add col with measurement approaches \n",
    "mandf2['method'] = 'manual 2'\n",
    "mandf1['method'] = 'manual 1'\n",
    "\n",
    "# add col with site \n",
    "mandf2['site'] = 'kentland'\n",
    "mandf1['site'] = 'kentland'\n",
    "\n",
    "mandf1_clean = mandf1.drop([\"Height (ft)\", \"DBH (In)\"], axis = 1)\n",
    "mandf2_clean = mandf2.drop([\"Height (ft)\", \"DBH (In)\"], axis = 1)\n",
    "\n",
    "# Merge back\n",
    "manual_10_22= pd.merge(mandf1_clean, mandf2_clean, right_on=['Row#','Tree#'], left_on = ['Row#','Tree#'], how='outer')\n",
    "manual_10_22['height_mean'] = manual_10_22[['height_1','height_2']].mean(axis = 1)\n",
    "manual_10_22['diam_mean'] = manual_10_22[['diam_1','diam_2']].mean(axis = 1)\n",
    "\n",
    "# Filtering of app data \n",
    "appdf.loc[appdf[\"species\"] == 'Black Locust', 'species'] = \"Black Walnut\"\n",
    "appdf.loc[appdf[\"species\"] == 'Honey locust', 'species'] = \"Honey Locust\"\n",
    "appdf.rename(columns = {\"parcel_id\":\"user\"}, inplace = True)\n",
    "\n",
    "data1 = pd.DataFrame(appdf[appdf['user']=='User 1'][['diam','user','species']])\n",
    "data2 = pd.DataFrame(appdf[appdf['user']=='User 1 repeat'][['diam','user','species']])\n",
    "data3 = pd.DataFrame(appdf[appdf['user']=='User 2'][['diam','user','species']])\n",
    "\n",
    "# Filtering of manual data \n",
    "manual_10_22.loc[manual_10_22[\"Species_x\"] == 'Honeylocust', 'species'] = \"Honey Locust\"\n",
    "manual_10_22.loc[manual_10_22[\"Species_x\"] == 'Blackwalnut', 'species'] = \"Black Walnut\"\n",
    "manual_10_22.loc[manual_10_22[\"Species_y\"] == 'Blackwalnut', 'species'] = \"Black Walnut\"\n",
    "manual_10_22.loc[manual_10_22[\"Species_y\"] == 'Blackwalnut', 'species'] = \"Black Walnut\"\n",
    "manual_10_22.loc[manual_10_22[\"method_x\"] == 'manual 1', 'method'] = \"manual 1\"\n",
    "manual_10_22.loc[manual_10_22[\"method_y\"] == 'manual 2', 'method'] = \"manual 2\"\n",
    "# manual_10_22.rename(columns = {'method_x':'user', 'method_y':'user'}, inplace = True)\n",
    "\n",
    "m1 = manual_10_22[['diam_1','method_x','species']].rename(columns = {'diam_1':'diam','method_x':'user'})\n",
    "m2 = manual_10_22[['diam_2','method_y','species']].rename(columns = {'diam_2':'diam','method_y':'user'})\n",
    "# m2['user'] = 'manual 2'\n",
    "\n",
    "cdf = pd.concat([data1, data2, data3,m1,m2])    \n",
    "# mdf = pd.melt(cdf, id_vars=['species'], var_name=['user'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea722535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (9,6))\n",
    "ax = sns.violinplot(x=\"species\", y=\"diam\", hue=\"user\", data=cdf)\n",
    "\n",
    "medians = cdf.groupby(['user','species'])['diam'].median()\n",
    "nobs =  cdf.groupby(['user','species']).apply(lambda x: 'n={}'.format(len(x)))\n",
    "\n",
    "for ax in plt.gcf().axes:\n",
    "\n",
    "    for tick, label in enumerate(ax.get_xticklabels()):\n",
    "        ax_species = label.get_text()\n",
    "\n",
    "        for j, ax_user in enumerate(ax.get_legend_handles_labels()[1]):\n",
    "            x_offset = (j - (5-1)/2) * (5/((5*1)+1-1)) * 0.16\n",
    "            med_val = medians[ax_user, ax_species] - 2.\n",
    "            num = nobs[ax_user, ax_species]\n",
    "\n",
    "            ax.text(tick + x_offset, med_val, num,\n",
    "                    horizontalalignment='center', size='large', color='w', weight='semibold')\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "plt.legend(title = None, loc = 'upper left')\n",
    "plt.ylabel(\"diameter (cm)\", size = 16)\n",
    "plt.xlabel(\"\")\n",
    "plt.title(\"Diameter summary for each species and user\", size = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0524fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14f0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge app + manual \n",
    "kentland_df = pd.merge(appdf, manual_10_22,  how='left', right_on=['Row#','Tree#'], left_on = ['row','tree_idx']).dropna()\n",
    "# kentland_df.rename(columns = {'diam_x':'diam_app', 'diam_y':'diam', 'height_x':'height_app', 'height_y':'height', 'Species':'species'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set col names \n",
    "kentland_df['species'] = kentland_df['species_x'].replace(\"Honeylocust\", \"Honey Locust\")\n",
    "kentland_df['species'] = kentland_df['species_x'].replace(\"Blacklocust\", \"Black Locust\")\n",
    "kentland_df['species'] = kentland_df['species_x'].replace(\"Blackwalnut\", \"Black Walnut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f8590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write\n",
    "kentland_df.to_csv(\"../data/kentland_10_22.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a248338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931beedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bde333",
   "metadata": {},
   "outputs": [],
   "source": [
    "udfs = []\n",
    "\n",
    "for u in cdf.user.unique():\n",
    "#     cdf = cdf[cdf['species'] == \"Black Walnut\"]\n",
    "    udf = cdf[cdf['user'] == u].drop([\"user\",'species'],axis = 1)\n",
    "    udft = udf.reset_index().drop(['index'], axis = 1)\n",
    "    udft.columns = [u]\n",
    "    udfs.append(udft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88449ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "anovadf = pd.concat(udfs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacffb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/1\n",
    "print(\"U1 M1\")\n",
    "print(stats.f_oneway(anovadf['User 1'].dropna(), anovadf['manual 1'].dropna()))\n",
    "print(stats.levene(anovadf['User 1'].dropna(), anovadf['manual 1'].dropna()))\n",
    "\n",
    "# 2/1\n",
    "print(\"U2 M1\")\n",
    "print(stats.f_oneway(anovadf['User 1 repeat'].dropna(), anovadf['manual 1'].dropna()))\n",
    "print(stats.levene(anovadf['User 1 repeat'].dropna(), anovadf['manual 1'].dropna()))\n",
    "\n",
    "# 3/1\n",
    "print(\"U3 M1\")\n",
    "print(stats.f_oneway(anovadf['User 2'].dropna(), anovadf['manual 1'].dropna()))\n",
    "print(stats.levene(anovadf['User 2'].dropna(), anovadf['manual 1'].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/2\n",
    "print(\"U1 M2\")\n",
    "print(stats.f_oneway(anovadf['User 1'].dropna(), anovadf['manual 2'].dropna()))\n",
    "print(stats.levene(anovadf['User 1'].dropna(), anovadf['manual 2'].dropna()))\n",
    "\n",
    "# 2/2\n",
    "print(\"U2 M2\")\n",
    "print(stats.f_oneway(anovadf['User 1 repeat'].dropna(), anovadf['manual 2'].dropna()))\n",
    "print(stats.levene(anovadf['User 1 repeat'].dropna(), anovadf['manual 2'].dropna()))\n",
    "\n",
    "# 3/2\n",
    "print(\"U3 M2\")\n",
    "print(stats.f_oneway(anovadf['User 2'].dropna(), anovadf['manual 2'].dropna()))\n",
    "print(stats.levene(anovadf['User 2'].dropna(), anovadf['manual 2'].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd1259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52094d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating the t-test for two independent samples\n",
    "def independent_ttest(data1, data2, alpha):\n",
    "    # calculate means\n",
    "    mean1, mean2 = np.nanmean(data1), np.nanmean(data2)\n",
    "    # calculate standard errors\n",
    "    se1, se2 = stats.sem(data1), stats.sem(data2)\n",
    "    # standard error on the difference between the samples\n",
    "    sed = np.sqrt(se1**2.0 + se2**2.0)\n",
    "    # calculate the t statistic\n",
    "    t_stat = (mean1 - mean2) / sed\n",
    "    # degrees of freedom\n",
    "    df = len(data1) + len(data2) - 2\n",
    "    # calculate the critical value\n",
    "    cv = stats.t.ppf(1.0 - alpha, df)\n",
    "    # calculate the p-value\n",
    "    p = (1.0 - stats.t.cdf(abs(t_stat), df)) * 2.0\n",
    "    # return everything\n",
    "    return t_stat, df, cv, p\n",
    "\n",
    "def dependent_ttest(data1, data2, alpha):\n",
    "\n",
    "    if not len(data1.dropna()) == len(data2.dropna()):\n",
    "        dat = pd.merge(data1,data2, left_index = True, right_index = True).dropna()\n",
    "        data1, data2 = dat.iloc[:,0], dat.iloc[:,1]\n",
    "\n",
    "    # calculate means\n",
    "    mean1, mean2 = np.nanmean(data1), np.nanmean(data2)\n",
    "    # number of paired samples\n",
    "    n = len(data2)\n",
    "    # sum squared difference between observations\n",
    "    d1 = sum([(data1[i]-data2[i])**2 for i in range(n)])\n",
    "    # sum difference between observations\n",
    "    d2 = sum([data1[i]-data2[i] for i in range(n)])\n",
    "    # standard deviation of the difference between means\n",
    "    sd = np.sqrt((d1 - (d2**2 / n)) / (n - 1))\n",
    "    # standard error of the difference between the means\n",
    "    sed = sd / np.sqrt(n)\n",
    "    # calculate the t statistic\n",
    "    t_stat = (mean1 - mean2) / sed\n",
    "    # degrees of freedom\n",
    "    df = n - 1\n",
    "    # calculate the critical value\n",
    "    cv = stats.t.ppf(1.0 - alpha, df)\n",
    "    # calculate the p-value\n",
    "    p = (1.0 - stats.t.cdf(abs(t_stat), df)) * 2.0\n",
    "    # return everything\n",
    "    return t_stat, df, cv, p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155873f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "t_stat, df, cv, p = independent_ttest(anovadf['User 1'].dropna(), anovadf['manual 2'].dropna(), 0.05)\n",
    "\n",
    "print('t=%.3f, df=%d, cv=%.3f, p=%.3f' % (t_stat, df, cv, p))\n",
    "\n",
    "# interpret via critical value\n",
    "if abs(t_stat) <= cv:\n",
    "    print('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "    print('Reject the null hypothesis that the means are equal.')\n",
    "\n",
    "# interpret via p-value\n",
    "if p > alpha:\n",
    "    print('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "    print('Reject the null hypothesis that the means are equal.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc50ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "t_stat, df, cv, p, n = dependent_ttest(anovadf['User 1'], anovadf['manual 2'], 0.05)\n",
    "\n",
    "print('t=%.3f, df=%d, cv=%.3f, p=%.3f n=%.3f' % (t_stat, df, cv, p, n))\n",
    "\n",
    "# interpret via critical value\n",
    "if abs(t_stat) <= cv:\n",
    "    print('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "    print('Reject the null hypothesis that the means are equal.')\n",
    "\n",
    "# interpret via p-value\n",
    "if p > alpha:\n",
    "    print('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "    print('Reject the null hypothesis that the means are equal.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe5c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = ['User 1','User 1 repeat','User 2']\n",
    "group2 = ['manual 1', 'manual 2']\n",
    "\n",
    "combos = list(itertools.product(group1,group2))\n",
    "\n",
    "f_stats = pd.DataFrame(columns = group2, index = group1).astype(float)\n",
    "f_stats_p = pd.DataFrame(columns = group2, index = group1).astype(float)\n",
    "f_odf = pd.DataFrame(columns = group2, index = group1)\n",
    "\n",
    "l_stats = pd.DataFrame(columns = group2, index = group1).astype(float)\n",
    "l_stats_p = pd.DataFrame(columns = group2, index = group1).astype(float)\n",
    "l_odf = pd.DataFrame(columns = group2, index = group1)\n",
    "\n",
    "t_stats = pd.DataFrame(columns = group2, index = group1).astype(float)\n",
    "t_stats_p = pd.DataFrame(columns = group2, index = group1).astype(float)\n",
    "t_odf = pd.DataFrame(columns = group2, index = group1)\n",
    "\n",
    "it_stats = pd.DataFrame(columns = group2, index = group1).astype(float)\n",
    "it_stats_p = pd.DataFrame(columns = group2, index = group1).astype(float)\n",
    "it_odf = pd.DataFrame(columns = group2, index = group1)\n",
    "\n",
    "\n",
    "for combo in combos:\n",
    "    v1 = combo[0]\n",
    "    v2 = combo[1]\n",
    "    \n",
    "    levene, lp = stats.levene(anovadf[v1].dropna(), anovadf[v2].dropna())\n",
    "    l_stats.loc[combo] = levene\n",
    "    l_stats_p.loc[combo] = lp\n",
    "    l_odf.loc[combo] = (str(round(levene,2)) + \" ({})\".format(str(round(lp,4))))\n",
    "    \n",
    "    f_test, fp = stats.f_oneway(anovadf[v1].dropna(), anovadf[v2].dropna())\n",
    "    f_stats.loc[combo] = f_test\n",
    "    f_stats_p.loc[combo] = fp\n",
    "    f_odf.loc[combo] = (str(round(f_test,2)) + \" ({})\".format(str(round(fp,4))))\n",
    "    \n",
    "    t_stat, df, cv, p, n = dependent_ttest(anovadf[v1], anovadf[v2], 0.05)\n",
    "    t_odf.loc[combo] = (str(round(t_stat,2)) + \" ({})\".format(str(round(p,4))))\n",
    "\n",
    "    t_stat, df, cv, p, n = dependent_ttest(anovadf[v1], anovadf[v2], 0.05)\n",
    "    t_odf.loc[combo] = (str(round(t_stat,2)) + \" ({})\".format(str(round(p,4))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a002d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_odf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_odf.to_csv(\"../results/kentland_10_22/t_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b75d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc15842",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_odf.to_csv(\"../results/kentland_10_22/f_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db63eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707aa71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_odf.to_csv(\"../results/kentland_10_22/l_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c014e",
   "metadata": {},
   "source": [
    "# Uncertainty Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc454973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenkins equtions For mixed hardwoods \n",
    "\n",
    "def biom_f_dbh(dbh, treetype = 'mixed hardwoods'):\n",
    "        \n",
    "    if treetype == 'mixed hardwoods':\n",
    "        return np.exp(-2.4800  + 2.4835 *np.log(dbh))\n",
    "    if treetype == 'pine':\n",
    "        return np.exp(-2.5356  + 2.4349 *np.log(dbh))\n",
    "    else:\n",
    "        return \"Specify species\"\n",
    "    \n",
    "for user in ['User 1', 'User 1 repeat', 'User 2', 'manual 1', 'manual 2']:\n",
    "    # Convert app user measurements of carbo \n",
    "    carbon_df = biom_f_dbh(anovadf[user]) * 0.001 * 44/12 * 0.5 # kg --> T, T C --> T Co2e, C fraction\n",
    "    samp_var = np.nansum(((carbon_df - np.nanmean(carbon_df))**2)) / len(carbon_df.dropna()-1)\n",
    "    samp_std = np.sqrt(samp_var)\n",
    "    t_crit = 1.65 # for a p value of 0.05\n",
    "    mean_carbon_per_tree = np.nanmean(carbon_df)\n",
    "    print(\"USER = {}\".format(user))\n",
    "    print(\"N trees measured = {}\".format(len(carbon_df.dropna()-1)))\n",
    "    print(\"mean carbon per tree = {} +/- {}\".format(mean_carbon_per_tree, samp_var))\n",
    "    print(\"per tree st dev. = {}\".format(samp_std))\n",
    "    unc_ded = t_crit * samp_var / mean_carbon_per_tree\n",
    "    print(\"computed uncertainty (T CO2e) = {}\".format(unc_ded))\n",
    "    print(\"uncertainty as % of mean = {}\".format(unc_ded/mean_carbon_per_tree))\n",
    "    print(\"-----\" * 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098034c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anovadf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4883ae00",
   "metadata": {},
   "source": [
    "# Make all combinations of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "catawba = pd.read_csv(\"../data/catawba_05_22.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec7cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tlist = []\n",
    "\n",
    "# For each tree (unique row / col combo index), calculate mean and variance for errorbar plots \n",
    "for ridx in appdf['row'].unique()[:]:\n",
    "    ardf = appdf[appdf['row']==ridx]\n",
    "    mrdf = manual_10_22[manual_10_22['Row#'] == ridx]\n",
    "    for tidx in appdf['tree_idx'].unique()[:]:\n",
    "        atdf = ardf[ardf['tree_idx'] == tidx]\n",
    "        mtdf = mrdf[mrdf['Tree#'] == tidx]\n",
    "        if len(atdf) > 0 and len(mtdf) > 0:\n",
    "            manvals = np.array([mtdf['diam_1'].values[0], mtdf['diam_2'].values[0]])\n",
    "            appvals = atdf['diam'].values\n",
    "            c = list(itertools.product(manvals, appvals))\n",
    "            mans = [x[0] for x in set(c)]\n",
    "            apps = [x[1] for x in set(c)]\n",
    "            unq_tree_df = pd.DataFrame([mans,apps]).T\n",
    "            unq_tree_df.columns = ['manual','app']\n",
    "            unq_tree_df['species'] = atdf['species'].values[0]\n",
    "            unq_tree_df['site'] = 'kentland'\n",
    "            \n",
    "            tlist.append(unq_tree_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d093dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combos = pd.concat(tlist, axis = 0).reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e7b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "catdf = pd.DataFrame([catawba['diam'].values, catawba['diam_app'].values, catawba['species'].values]).T\n",
    "catdf['site'] = 'catawba'\n",
    "catdf.columns = ['manual','app','species','site']\n",
    "\n",
    "all_data = pd.concat([all_combos,catdf], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "diam_all = all_data.copy().dropna()\n",
    "\n",
    "# Diam linear regression grouped by species \n",
    "\n",
    "groups = diam_all.groupby('species')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.plot(group['manual'], group['app'], marker='o', linestyle='', ms=7, label=name, alpha = 0.5)\n",
    "    \n",
    "# Plot 1-1 line\n",
    "ax.plot([0,300],[0,300],'k-', lw=2, label = '1-1 line')\n",
    "\n",
    "# Compute regression \n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(diam_all['manual'].astype(float), diam_all['app'].astype(float))\n",
    "\n",
    "# Mean absolute error\n",
    "mae = np.nanmean((diam_all['app'] - diam_all['manual']))\n",
    "mae_std = np.nanstd(abs(diam_all['app'] - diam_all['manual']))\n",
    "mape = np.nanmean(((diam_all['app'] - diam_all['manual']) / diam_all['manual'])) * 100\n",
    "mape_std = np.nanstd(((diam_all['app'] - diam_all['manual']) / diam_all['manual'])) * 100\n",
    "rmse = ((diam_all['app'] - diam_all['manual']) ** 2).mean() ** .5\n",
    "\n",
    "# regression line \n",
    "line = slope*np.linspace(0,300)+ intercept\n",
    "plt.plot(np.linspace(0,300), line, 'r', label='y={:.2f}x+{:.2f}'.format(slope,intercept))\n",
    "plt.annotate(\"$R^2$ = {}\".format(str(r_value**2)[:5]), [25,13], size = 14)\n",
    "plt.annotate(\"$p$ = {:.2e}\".format(p_value), [25,10], size = 14)\n",
    "plt.annotate(\"Mean err = {} +/- {} cm\".format(str(round(mae,5))[:5],str(round(mae_std,2))), [25,7], size = 14)\n",
    "plt.annotate(\"Mean % err = {} +/- {} %\".format(str(round(mape,5))[:5],str(round(mape_std,2))), [25,4], size = 14)\n",
    "plt.annotate(\"RMSE = {} cm\".format(str(round(rmse,5))[:5],), [25,1], size = 14)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlim(0,50)\n",
    "ax.set_ylim(0,50)\n",
    "    \n",
    "plt.xlabel(\"manual diameter (cm)\", size = 16)\n",
    "plt.ylabel(\"app-based diameter (cm)\", size = 16)\n",
    "\n",
    "\n",
    "titlestr = \"Diameter (cm), N = {}\".format(str(len(diam_all)))\n",
    "plt.title(titlestr, size = 20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(figsize = (9,7))\n",
    "\n",
    "sns.scatterplot(data = diam_all, x = 'manual', y = 'app', \n",
    "                hue = 'species', style = 'site', s = 100, alpha = 0.65, ax = ax)\n",
    "\n",
    "# Plot 1-1 line\n",
    "ax.plot([0,300],[0,300],'k-', lw=2, label = '1-1 line')\n",
    "\n",
    "# Compute regression \n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(diam_all['manual'].astype(float), diam_all['app'].astype(float))\n",
    "\n",
    "# Mean absolute error\n",
    "mae = np.nanmean((diam_all['app'] - diam_all['manual']))\n",
    "mae_std = np.nanstd(abs(diam_all['app'] - diam_all['manual']))\n",
    "mape = np.nanmean(((diam_all['app'] - diam_all['manual']) / diam_all['manual'])) * 100\n",
    "mape_std = np.nanstd(((diam_all['app'] - diam_all['manual']) / diam_all['manual'])) * 100\n",
    "rmse = ((diam_all['app'] - diam_all['manual']) ** 2).mean() ** .5\n",
    "\n",
    "# regression line \n",
    "line = slope*np.linspace(0,300)+ intercept\n",
    "plt.plot(np.linspace(0,300), line, 'r', label='y={:.2f}x+{:.2f}'.format(slope,intercept))\n",
    "plt.annotate(\"$R^2$ = {}\".format(str(r_value**2)[:5]), [25,13], size = 14)\n",
    "plt.annotate(\"$p$ = {:.2e}\".format(p_value), [25,10], size = 14)\n",
    "plt.annotate(\"Mean err = {} +/- {} cm\".format(str(round(mae,5))[:5],str(round(mae_std,2))), [25,7], size = 14)\n",
    "plt.annotate(\"Mean % err = {} +/- {} %\".format(str(round(mape,5))[:5],str(round(mape_std,2))), [25,4], size = 14)\n",
    "plt.annotate(\"RMSE = {} cm\".format(str(round(rmse,5))[:5],), [25,1], size = 14)\n",
    "\n",
    "ax.legend(fontsize = 13)\n",
    "ax.set_xlim(0,50)\n",
    "ax.set_ylim(0,50)\n",
    "    \n",
    "plt.xlabel(\"manual diameter (cm)\", size = 16)\n",
    "plt.ylabel(\"app-based diameter (cm)\", size = 16)\n",
    "\n",
    "\n",
    "titlestr = \"Diameter (cm), N = {}\".format(str(len(diam_all)))\n",
    "plt.title(titlestr, size = 20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90085835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance_corr_coeff(x,y,correlation):\n",
    "    numerator = 2 * correlation * np.nanstd(x) * np.nanstd(y)\n",
    "    denom = np.nanstd(x)**2 + np.nanstd(y)**2  + (np.nanmean(x) - np.nanmean(y)) ** 2\n",
    "    return numerator/denom\n",
    "\n",
    "def intra_class_corr(x,y):\n",
    "    N = len(x)\n",
    "    x_bar = (1 / (2 * N)) * np.nansum(x+y)\n",
    "    s_sq = (1 / (2 * N)) * ( np.nansum((x - x_bar)**2) + np.nansum((y - x_bar)**2) ) \n",
    "    ICC = (1 / (N * s_sq)) * np.nansum( (x-x_bar ) * (y - x_bar) )\n",
    "    \n",
    "    return ICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86753880",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(concordance_corr_coeff(diam_all['app'],diam_all['manual'],r_value))\n",
    "print(intra_class_corr(diam_all['app'],diam_all['manual']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f44c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_table_rows = []\n",
    "\n",
    "for sp in diam_all['species'].unique():\n",
    "    ddf = diam_all[diam_all['species']==sp]\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(ddf['app'].astype(float), ddf['manual'].astype(float))\n",
    "    cc = concordance_corr_coeff(ddf['app'], ddf['manual'], correlation = r_value)\n",
    "    icc = intra_class_corr(ddf['app'],ddf['manual'])\n",
    "    rmse = ((ddf['app'] - ddf['manual']) ** 2).mean() ** .5\n",
    "    mean_error = (ddf['app']-ddf['manual']).mean()\n",
    "    mpe = np.nanmean((ddf['app']-ddf['manual'])/ddf['manual'])*100\n",
    "    rsq = r_value**2\n",
    "    num_samples = len(ddf)\n",
    "    print(\"=======\"*5)\n",
    "    print(sp  + \" N = {}\".format(len(ddf)))\n",
    "    print(\"Mean error = {}\".format(mean_error))\n",
    "    print(\"Mean Pct error = {}\".format(mpe))\n",
    "    print(\"R2 = {}\".format(rsq))\n",
    "    print(\"RMSE = {}\".format(rmse))\n",
    "    print(\"concordance correlation coeff = {}\".format(cc))\n",
    "    print(\"intraclass correlation coeff = {}\".format(icc))\n",
    "    \n",
    "    statdf = pd.DataFrame([num_samples,mean_error,mpe,rmse,rsq,cc,icc])\n",
    "    statdf.columns = [sp]\n",
    "    statdf.index = ['N','ME','MPE','RMSE','$R^2$','$p_c$','$r$']\n",
    "    out_table_rows.append(statdf)\n",
    "    \n",
    "#     print(stats.levene(ddf['manual'],ddf['app'], center= 'mean'))\n",
    "#     print(stats.ttest_rel(ddf['manual'],ddf['app']))\n",
    "#     print(stats.ttest_ind(ddf['manual'],ddf['app'], equal_var = False))\n",
    "#     print(stats.wilcoxon(ddf['manual'],ddf['app']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(out_table_rows, axis = 1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(out_table_rows, axis = 1).T.to_csv(\"../results/Table1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf91d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin Plots \n",
    "diam_all['manual'] = diam_all['manual'].astype(float)\n",
    "diam_all['app'] = diam_all['app'].astype(float)\n",
    "\n",
    "diam_all['mae'] = diam_all['app'] - diam_all['manual']\n",
    "diam_all['mpe'] = (diam_all['app'] - diam_all['manual']) / diam_all['manual'] * 100\n",
    "\n",
    "# Boxplot of error \n",
    "plt.figure(figsize = (8,4))\n",
    "ax = sns.violinplot(x=\"species\", y=\"mpe\", data=diam_all)\n",
    " \n",
    "# Calculate number of obs per group & median to position labels\n",
    "medians = diam_all.dropna().groupby(['species'])['mpe'].mean().values\n",
    "nobs = diam_all['species'].value_counts().values\n",
    "nobs = [str(x) for x in nobs.tolist()]\n",
    "nobs = [\"n: \" + i for i in nobs]\n",
    " \n",
    "# Add it to the plot\n",
    "pos = range(len(nobs))\n",
    "for tick,label in zip(pos,ax.get_xticklabels()):\n",
    "    ax.text(pos[tick],\n",
    "             - 57.5,\n",
    "            nobs[tick],\n",
    "            horizontalalignment='center',\n",
    "            size='large',\n",
    "            color='black',\n",
    "            weight='semibold')\n",
    "plt.ylabel(\"Percent error\", size = 25)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid() \n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d753ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of error \n",
    "plt.figure(figsize = (8,4))\n",
    "ax = sns.violinplot(x=\"species\", y=\"mae\", data=diam_all)\n",
    " \n",
    "# Calculate number of obs per group & median to position labels\n",
    "medians =diam_all.dropna().groupby(['species'])['mae'].mean().values\n",
    "nobs = diam_all['species'].value_counts().values\n",
    "nobs = [str(x) for x in nobs.tolist()]\n",
    "nobs = [\"n= \" + i for i in nobs]\n",
    " \n",
    "# Add it to the plot\n",
    "pos = range(len(nobs))\n",
    "for tick,label in zip(pos,ax.get_xticklabels()):\n",
    "    ax.text(pos[tick],\n",
    "             - 8.75,\n",
    "            nobs[tick],\n",
    "            horizontalalignment='center',\n",
    "            size='large',\n",
    "            color='black',\n",
    "            weight='semibold')\n",
    "plt.ylabel(\"Error (cm)\", size = 25)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid() \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ece712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bland Altman Plot \n",
    "\n",
    "f, ax = plt.subplots(1, figsize = (8,5))\n",
    "sm.graphics.mean_diff_plot(diam_all['app'], diam_all['manual'],  ax = ax)\n",
    "plt.title(\"Bland-Altman Plot for Tree Diameter (cm)\", size = 25)\n",
    "\n",
    "plt.show() \n",
    "\n",
    "# 8\n",
    "print(\"{} % of the data falls within 95% Diameter CI\".format(str(round((100 - ((8/len(diam_all)) * 100)),3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7acd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,3))\n",
    "sns.histplot(diam_all, x=\"manual\", hue=\"species\", element=\"step\", kde = True, bins = 20)\n",
    "plt.xlim([0,50])\n",
    "plt.ylim([0,55])\n",
    "plt.title(\"Tape Measure\", size = 18)\n",
    "plt.xlabel(\"Manual Diameter (cm)\", size = 16)\n",
    "plt.ylabel(\"Count\", size = 16)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (8,3))\n",
    "sns.histplot(diam_all, x=\"app\", hue=\"species\", element=\"step\", kde = True, bins = 20)\n",
    "plt.xlim([0,50])\n",
    "plt.ylim([0,50])\n",
    "plt.title(\"Phone application\", size = 18)\n",
    "plt.xlabel(\"Mobile Diameter (cm)\", size = 16)\n",
    "plt.ylabel(\"Count\", size = 16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58746b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
